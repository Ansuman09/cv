{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ansuman09/cv/blob/main/REMY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbmLLNDU-Ike"
      },
      "outputs": [],
      "source": [
        "import json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pCypbdzmYyR"
      },
      "source": [
        "## REMY\n",
        "\n",
        "Creating the json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ai8LPPt5SqjS"
      },
      "outputs": [],
      "source": [
        "json_dict={'intents':[{\n",
        "    'tag': 'hello',\n",
        "    'patterns':['you up?','Hello','Hi','Heya','Hola','Hey there','Is any one there?'],\n",
        "    'responses':['Pleased to hear from you, Sir','I am here how can i assist you sir']\n",
        "},\n",
        "  {\n",
        "    'tag': 'goodbye',\n",
        "    'patterns': ['lets talk about it later','see you later','Goodbye','Bye'],\n",
        "    'responses':['Okay','I will be here if you need me','Have a great day']\n",
        "    },\n",
        "    {\"tag\": \"thanks\",\n",
        "     \"patterns\": [\"Thanks\", \"Thank you\", \"That's helpful\", \"Awesome, thanks\", \"Thanks for helping me\",'Nice talking to you'],\n",
        "     \"responses\": [\"Happy to help!\", \"Any time!\", \"My pleasure\",'You are welcome'],\n",
        "     },\n",
        "    {'tag':'jokes',\n",
        "     'patterns':['tell me a joke','tell me something i dont know','How smart are you'],\n",
        "     'responses':['Why did the programmers act so nice to the AI? Because it was really self conscious.',\n",
        "                  'If an AI simulation of a pop singer performs all over the world... Does that mean she passes the touring test?',\n",
        "                  'Don’t you hate it when someone answers their own questions? I do.',\n",
        "                  'I used to think I was indecisive. But now I’m not so sure.',\n",
        "                  'The future, the present, and the past walk into a bar. Things got a little tense.']},\n",
        "    {\"tag\": \"options\",\n",
        "    \"patterns\": [\"How you could help me?\", \"How you can be helpful?\", \"What support is offered\",'What can you do'],\n",
        "    \"responses\": [\"Inform you about the items at store such as availability, price and take orders... to place orders, visit this page\"],\n",
        "    },\n",
        "    {'tag':'make_orders',\n",
        "     'patterns':['I want to make an order','order this item'],\n",
        "     'responses':['Very well, click on this link to place your order']\n",
        "    },\n",
        "    {'tag':'delivery',\n",
        "     'patterns':['Do you make home delivery?','Deliver goods at home','Deliver copies at home'],\n",
        "     'responses':['I am afraid we dont provide such services as of now']\n",
        "    },\n",
        "    {'tag':'occassion',\n",
        "     'patterns':['What gift items do you have?','Suggest a gift item','occassion','what birthday gifts do you have'],\n",
        "     'responses':['We have gift envelopes, pencilboxes, Crayons, partypoppers, choclates and many more']  \n",
        "    },\n",
        "    {'tag':'available',\n",
        "     'patterns':['What kind of items do you have','What services do you provide','Do you have school utensils','What is available'],\n",
        "     'responses':['We have plain copies, ruled copies, paper, graphs, maps, charts and other project and study utensils in the shop']  \n",
        "    },\n",
        "    {'tag':'prices',\n",
        "     'patterns':['What does it cost?','How much is it','price?','Is it expensive'],\n",
        "     'responses':['The prices are reasonable','We offer the best price in the market']}\n",
        "    ]}\n",
        "with open('intents.json','w') as file:\n",
        "  json.dump(json_dict,file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gMp-_nI9DIEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's Import the Dependencies,\n",
        "\n",
        "we use nltk to tokenize the text and use the torch framework for building the NeuralNet"
      ],
      "metadata": {
        "id": "oXUkKsVqDKtm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bniO7pWsGJL",
        "outputId": "253f014f-a062-4346-9bad-c5870f6934e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "import numpy as np\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import urllib\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Neural Network"
      ],
      "metadata": {
        "id": "dYDnEsbKDm4Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNGd2j6RwHXR"
      },
      "outputs": [],
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,output_size):\n",
        "    \"\"\"\n",
        "    this function will take the input size i.e. the size of the arry, \n",
        "    the hidden layer size and output size that is the size of the labels array\n",
        "    and output a neural net\n",
        "    \"\"\"\n",
        "    super(NeuralNet,self).__init__()\n",
        "    self.l1=nn.Linear(input_size,hidden_size)\n",
        "    self.l2=nn.Linear(hidden_size,hidden_size)\n",
        "    self.l3=nn.Linear(hidden_size,output_size)\n",
        "    self.relu=nn.ReLU()\n",
        "\n",
        "  def forward(self,x):\n",
        "    out=self.l1(x)\n",
        "    out=self.relu(out)\n",
        "    out=self.l2(out)\n",
        "    out=self.relu(out)\n",
        "    out=self.l3(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "use porter stemmmer to stem words for example words like ..\n",
        "['go','gone','going'] could be considered as a single word 'go',"
      ],
      "metadata": {
        "id": "ZsGPlEG_ElqR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUBsSn540iVL",
        "outputId": "fb4bf48f-2a4d-487b-958e-976fb7eddd0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i\n",
            "like\n",
            "to\n",
            "eat\n",
            "like\n",
            "ice-cream\n"
          ]
        }
      ],
      "source": [
        "stemmer=PorterStemmer()\n",
        "\n",
        "def tokenizer(sentence):\n",
        "  return nltk.word_tokenize(sentence)\n",
        "\n",
        "def stem_w(word):\n",
        "  return stemmer.stem(word.lower())\n",
        "\n",
        "\n",
        "for n in tokenizer('i like to eat liking ice-cream'):\n",
        "  print(stem_w(n))\n",
        "\n",
        "def bag_of_words(tokenized_sentence,all_words):\n",
        "  tokenized_sentence=[stem_w(word) for word in tokenized_sentence]\n",
        "\n",
        "  bag=np.zeros(len(all_words),dtype=np.float32)\n",
        "  for idx,word in enumerate(all_words):\n",
        "    if word in tokenized_sentence:\n",
        "      bag[idx]=1\n",
        "  return bag\n",
        "\n",
        "#the words like and liking are treated as the same i.e. like"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code creates a bag of words that would be later used to mask each of the sentence. If our bag of words contain... ['wake', 'coffee'] then the mask we have implemented later would create an array for a givn line: 'I will wake up and make some cofffee' ..as [0 0 1 0 0 0 0 1] the values one means that the word used in the following sentence was in the bag of words. "
      ],
      "metadata": {
        "id": "rJNH4Ra0FTwF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVm9wr3__Oj_"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "url = 'intents.json'\n",
        "\n",
        "with open(url, 'r') as f:\n",
        "    intents = json.load(f)\n",
        "\n",
        "all_words=[]\n",
        "tags=[]\n",
        "xy=[]\n",
        "\n",
        "for intent in intents['intents']:\n",
        "  tag=intent['tag']\n",
        "  tags.append(tag)\n",
        "  for pattern in intent['patterns']:\n",
        "    w=tokenizer(pattern)\n",
        "    all_words.extend(w)\n",
        "    xy.append((w,tag))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPLcac4HBd63"
      },
      "outputs": [],
      "source": [
        "ignore_words=['?','!','.',',']\n",
        "all_words=[stem_w(word) for word in all_words if word not in ignore_words]\n",
        "\n",
        "all_words=sorted(set(all_words))\n",
        "tags=sorted(set(tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LFasGwGBeAH"
      },
      "outputs": [],
      "source": [
        "#creating the train set and labels the labels are the tags in intents.json created earlier\n",
        "X_train=[]\n",
        "y_train=[]\n",
        "for tokenized_text,tag in xy:\n",
        "  bag=bag_of_words(tokenized_text,all_words)\n",
        "  X_train.append(bag)\n",
        "  \n",
        "  label=tags.index(tag)\n",
        "  y_train.append(label)\n",
        "\n",
        "X_train=np.array(X_train)\n",
        "y_train=np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9RT-J9Llj8T",
        "outputId": "a3d30a13-0bb1-4c47-f228-0ea4060228a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(74,)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is how the bag of words works"
      ],
      "metadata": {
        "id": "qnsnHRSYGVhE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC2EiESPFhrh",
        "outputId": "4499a312-d26c-43bf-de7e-12f7e99c17bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words dict       : [\"'s\", 'a', 'about', 'an', 'ani', 'are', 'at', 'avail', 'awesom', 'be', 'birthday', 'bye', 'can', 'copi', 'cost', 'could', 'deliv', 'deliveri', 'do', 'doe', 'dont', 'expens', 'for', 'gift', 'good', 'goodby', 'have', 'hello', 'help', 'hey', 'heya', 'hi', 'hola', 'home', 'how', 'i', 'is', 'it', 'item', 'joke', 'kind', 'know', 'later', 'let', 'make', 'me', 'much', 'nice', 'occass', 'of', 'offer', 'one', 'order', 'price', 'provid', 'school', 'see', 'servic', 'smart', 'someth', 'suggest', 'support', 'talk', 'tell', 'thank', 'that', 'there', 'thi', 'to', 'up', 'utensil', 'want', 'what', 'you']\n",
            "tokenized_words  : ['you', 'up', '?'],['Hello'],['Hi']\n",
            "train_set        : [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            "  0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0.]]\n",
            "labels           : [3 3 3]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(f'Words dict       : {all_words}')\n",
        "print(f'tokenized_words  : {xy[0][0]},{xy[1][0]},{xy[2][0]}')\n",
        "print(f'train_set        : {X_train[:5]}')\n",
        "print(f'labels           : {y_train[:3]}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating a torch dataset to use our train set"
      ],
      "metadata": {
        "id": "s94AZk5GGjvR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fiHXA81Hmtb"
      },
      "outputs": [],
      "source": [
        "class ChatDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.n_samples=len(X_train)\n",
        "    self.x_data=X_train\n",
        "    self.y_data=y_train \n",
        "  \n",
        "  def __getitem__(self,index):\n",
        "    return self.x_data[index],self.y_data[index]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.n_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model"
      ],
      "metadata": {
        "id": "NejmUB59Gth7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVnYoo69HHVY",
        "outputId": "25a06d5d-9b5b-476d-d9b2-ddf6cc99725b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 100/1000, Loss is=0.000350175570929423\n",
            "epoch 200/1000, Loss is=9.42901024245657e-05\n",
            "epoch 300/1000, Loss is=4.434487345861271e-05\n",
            "epoch 400/1000, Loss is=5.722029527532868e-06\n",
            "epoch 500/1000, Loss is=9.65590606938349e-06\n",
            "epoch 600/1000, Loss is=3.790783375734463e-05\n",
            "epoch 700/1000, Loss is=1.5497195136049413e-06\n",
            "epoch 800/1000, Loss is=1.3112935448589269e-05\n",
            "epoch 900/1000, Loss is=1.0967194612021558e-05\n",
            "epoch 1000/1000, Loss is=1.1920922133867862e-06\n",
            "Final Loss, loss0.0000\n"
          ]
        }
      ],
      "source": [
        "batch_size=8\n",
        "hidden_dim=8\n",
        "output_dim=len(tags)\n",
        "input_dim=len(X_train[0])\n",
        "learning_rate=0.01\n",
        "num_epochs=1000\n",
        "\n",
        "dataset=ChatDataset()\n",
        "batched_data=DataLoader(dataset=dataset,batch_size=batch_size,shuffle=True,num_workers=2)\n",
        "\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model=NeuralNet(input_dim,hidden_dim,output_dim)\n",
        "\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for (words,labels) in batched_data:\n",
        "    words=words.to(device)\n",
        "    labels=labels.to(device)\n",
        "\n",
        "    output=model(words)\n",
        "    loss=criterion(output,labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  if (epoch+1)%100 == 0:\n",
        "    print(f'epoch {epoch+1}/{num_epochs}, Loss is={loss}')\n",
        "\n",
        "print(\"Final Loss, loss{:.4f}\".format(loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the model as data.pth to use in the tk inter app"
      ],
      "metadata": {
        "id": "COzbWHZiG2qi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rzc1Fsdrg7J2",
        "outputId": "c328d494-24a2-4af0-a108-f2daec99bfd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traning complete. file saved to data.pth\n"
          ]
        }
      ],
      "source": [
        "data = {\n",
        "    \"model_state\":model.state_dict(),\n",
        "    \"input_size\":input_dim,\n",
        "    \"output_size\":output_dim,\n",
        "    \"hiddent_size\": hidden_dim,\n",
        "    \"all_words\":all_words,\n",
        "    \"tags\": tags\n",
        "}\n",
        "FILE = \"data.pth\"\n",
        "torch.save(data, FILE)\n",
        "\n",
        "print(\"Traning complete. file saved to\",FILE)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "REMY.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMGvv9RkuHqlMKtd7AhXZGi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}